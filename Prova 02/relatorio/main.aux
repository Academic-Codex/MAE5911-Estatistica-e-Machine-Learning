\relax 
\providecommand\zref@newlabel[2]{}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\citation{abnt-url-package=url}
\babel@aux{portuguese}{}
\@writefile{toc}{\contentsline {paragraph}{Resultado final:}{3}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces \textbf  {Definição} dos blocos de multi-head attention treináveis}}{3}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}{\ignorespaces \textbf  {Definição} da Máscara causal}}{3}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}{\ignorespaces \textbf  {Cálculo} da atenção multi-cabeças mascarada em cada camada}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Trechos do corpus utilizado no experimento, provenientes da obra completa de Shakespeare disponibilizado pelo Projeto Gutenberg.}}{4}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:corpus_shakespeare}{{1}{4}{}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Vocabulário extraido no corpus utilizado (obra completa de Shakespeare).}}{5}{}\protected@file@percent }
\newlabel{fig:vocabulario}{{2}{5}{}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Hiperparâmetros utilizados no modelo GPT treinado.}}{5}{}\protected@file@percent }
\newlabel{tab:hiperparametros}{{1}{5}{}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Arquitetura geral do modelo GPT utilizado no experimento.}}{6}{}\protected@file@percent }
\newlabel{fig:arquitetura}{{3}{6}{}{figure.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parâmetros treináveis do modelo GPT utilizado no experimento.}}{7}{}\protected@file@percent }
\newlabel{tab:parametros}{{2}{7}{}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Evolução da função de perda durante o treinamento: comparação entre as curvas de treino e de teste ao longo das 1200 épocas.}}{7}{}\protected@file@percent }
\newlabel{fig:loss}{{4}{7}{}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Trechos do texto gerado pelo modelo treinado.}}{8}{}\protected@file@percent }
\newlabel{fig:texto-gerado}{{5}{8}{}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Curva de perda do modelo sem o mecanismo de atenção.}}{9}{}\protected@file@percent }
\newlabel{fig:loss_noattn}{{6}{9}{}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Amostra de texto gerado pelo modelo treinado sem o bloco de atenção.}}{9}{}\protected@file@percent }
\newlabel{fig:sample_noattn}{{7}{9}{}{figure.7}{}}
\newlabel{lst:config-r}{{4}{9}{}{lstlisting.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}{\ignorespaces Configurações do experimento.}}{9}{}\protected@file@percent }
\newlabel{lst:gpt-r}{{5}{10}{}{lstlisting.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}{\ignorespaces Implementação do modelo.}}{10}{}\protected@file@percent }
\newlabel{lst:treino-r}{{6}{11}{}{lstlisting.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}{\ignorespaces Script de treinamento do modelo.}}{11}{}\protected@file@percent }
\newlabel{lst:generator-r}{{7}{13}{}{lstlisting.7}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7}{\ignorespaces Funções de codificação e geração de texto com top-k sampling.}}{13}{}\protected@file@percent }
\bibstyle{abntex2-alf}
\newlabel{lst:prompt-r}{{8}{14}{}{lstlisting.8}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {8}{\ignorespaces Script de geração de texto a partir de um prompt inicial.}}{14}{}\protected@file@percent }
\gdef \@abspage@last{14}
