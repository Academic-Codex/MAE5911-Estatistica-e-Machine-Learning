\paragraph{(a) \(g(\theta)=P_\theta(Z>1)\)}
\[\]
Integrando a função densidade de probabilidade $f(z_i,\theta)$ para encontrar $P_\theta(Z>1)$:
\[
    g(\theta)=P_\theta(Z>1)
    =\int_{1}^{\infty} f(z,\theta)\,dz
    =\int_{1}^{\infty} \theta e^{-\theta z}\,dz.
\]

Calculando a integral:
\[
    \int_{1}^{\infty} \theta e^{-\theta z}\,dz
    =\Big[-e^{-\theta z}\Big]_{z=1}^{\infty}
    =0-(-e^{-\theta})=e^{-\theta}.
\]

Portanto,
\[
    g(\theta)=e^{-\theta}.
\]

Pela \textbf{invariância do EMV}, o estimador de máxima verossimilhança de \(g(\theta)\) é
\[
    \widehat g_{MV}=g(\widehat\theta_{MV}).
\]

Já encontramos que \(\widehat\theta_{MV}=\dfrac{1}{\overline Z}\) para distribuição Exponencial, então:
\[
    \boxed{\widehat g_{MV}
        = e^{-\widehat\theta_{MV}}
        = \exp\!\left(-\frac{1}{\overline Z}\right)}.
\]

%------------------------------------------------------------

\paragraph{(b) \(g(\theta)=P_\theta(0.1<Z<1)\)}
\[\]
Integrando a função densidade de probabilidade $f(z_i,\theta)$ para encontrar $P_\theta(0.1<Z<1)$:
\[
    g(\theta)
    =P_\theta(0.1<Z<1)
    =\int_{0.1}^{1} f(z,\theta)\,dz
    =\int_{0.1}^{1} \theta e^{-\theta z}\,dz.
\]

Calculando a integral:
\[
    \int_{0.1}^{1} \theta e^{-\theta z}\,dz
    =\Big[-e^{-\theta z}\Big]_{z=0.1}^{1}
    =-e^{-\theta}\;-\big(-e^{-0.1\theta}\big)
    =e^{-0.1\theta}-e^{-\theta}.
\]

Logo,
\[
    g(\theta)=e^{-0.1\theta}-e^{-\theta}.
\]

Pela \textbf{invariância do EMV},
\[
    \widehat g_{MV}=g(\widehat\theta_{MV})
    =e^{-0.1\widehat\theta_{MV}}-e^{-\widehat\theta_{MV}}.
\]

Substituindo \(\widehat\theta_{MV}=\dfrac{1}{\overline Z}\), obtemos:
\[
    \boxed{\widehat g_{MV}
        = \exp\!\left(-\frac{0.1}{\overline Z}\right)
        - \exp\!\left(-\frac{1}{\overline Z}\right)}.
\]

%------------------------------------------------------------

\paragraph{(c) \(g(\theta)=\mathrm{Var}_\theta(Z)\)}
\[\]
A variância é definida por:

\[
    \mathrm{Var}(Z) = E_\theta(Z^2) - \bigl(E_\theta(Z)\bigr)^2.
\]

Pela definição de esperança para variáveis contínuas, sendo $h(z)$ a função de interesse:
\[
    E_\theta(h(Z)) = \int_{-\infty}^{\infty} h(z)\, f(z;\theta)\,dz.
\]

Em particular, a esperança do primeiro e segundo momentos de $Z$, são:
\[
    E_\theta(Z) = \int_0^\infty z \, \theta e^{-\theta z}\,dz,
    = \left[ -z e^{-\theta z} \right]_{0}^{\infty}
    + \int_{0}^{\infty} e^{-\theta z}\,dz
    = 0
    + \left[ -\frac{1}{\theta} e^{-\theta z} \right]_{0}^{\infty}
    = 0 + \left( 0 - \left(-\frac{1}{\theta}\right) \right)
    = \frac{1}{\theta}.
\]
e
\[
    E_\theta(Z^2)= \int_0^\infty z^2 \,\theta e^{-\theta z}\,dz
    = \int_0^\infty \left(\frac{y}{\theta}\right)^2 \theta e^{-y}\,\frac{dy}{\theta}
    = \frac{1}{\theta^2}\int_0^\infty y^2 e^{-y}\,dy
    = \frac{1}{\theta^2}\cdot 2!
    = \frac{2}{\theta^2}.
\]

Então:

\[
    \mathrm{Var}_\theta(Z)
    = E(Z^{2}) - [E(Z)]^{2}
    = \frac{2}{\theta^{2}} - \left(\frac{1}{\theta}\right)^{2}
    = \frac{1}{\theta^{2}}.
\]

Portanto:
\[
    g(\theta)=\mathrm{Var}_\theta(Z)
    = \frac{1}{\theta^{2}}.
\]

Pela \textbf{invariância do EMV},
\[
    \widehat g_{MV}=g(\widehat\theta_{MV})
    =\frac{1}{\hat\theta_{MV}^{2}}.
\]

Substituindo \(\widehat\theta_{MV}=\dfrac{1}{\overline Z}\), obtemos:
\[
    \boxed{\widehat g_{MV}=\bar{Z}^{2}}.
\]



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{(d) Sejam os dados observados: $(0{,}2,\,0{,}6,\,0{,}3,\,0{,}2,\,0{,}8,\,0{,}12)$, encontrar IC para ítens (a), (b) e (c)}
\[\]
Para a distribuição exponencial é possível encontrar o intervalo de confiança exato para $\theta$ utilizando $\chi^2$, já que

\[
    S \sim \text{Gamma}(n,\theta),
\]
E portanto podemos expressar o intervalo de confiança em termos de $\chi^2_{2n}$:
\[
    2\theta S \sim \chi^2_{2n}.
\]
Chegando a:
\[
    P\!\left( \chi^2_{2n,\alpha/2} \le 2\theta S \le \chi^2_{2n,1-\alpha/2} \right)=1-\alpha.
\]

Dividindo tudo por $2S>0$:
\[
    P\!\left(
    \frac{\chi^2_{2n,\alpha/2}}{2S}
    \le \theta \le
    \frac{\chi^2_{2n,1-\alpha/2}}{2S}
    \right)
    =1-\alpha.
\]
Mas vamos utilizar o método aproximado que é útil na maior parte das aplicações onde a distribuição não
terá possibilidade de cálculo do intervalo de confiança exato. Segue o desenvolvimento assintótico do EMV para a distribuição Exponencial.
%%%%%%%%%%%%%<

\subsection*{Distribuição aproximada de $\hat\theta_{MV}$}

Para um modelo paramétrico com densidade $f(z,\theta)$, a informação de Fisher é:
\[
    I(\theta)
    =
    \mathbb{E}_\theta \!\left[
        \left(
        \frac{\partial}{\partial \theta} \log f(z,\theta)
        \right)^2
        \right]
    =
    -\,\mathbb{E}_\theta \!\left[
        \frac{\partial^2}{\partial \theta^2} \log f(z,\theta)
        \right].
\]
A segunda derivada da função log-verossimilhança $\mathcal{L}(\theta, S)$ é
\[
    -\mathcal{L}''(\theta, S) = \frac{n}{\theta^2},
\]
logo a Informação de Fisher é
\[
    I(\theta)=\frac{n}{\theta^2}.
\]

Assintoticamente:
\[
    \hat\theta_{MV} \approx N\!\left(\theta,\,\frac{1}{nI(\theta)}\right) \iff
    \hat\theta_{MV} \approx N\!\left(\theta,\,\frac{\theta^2}{n}\right) \iff
    \frac{\hat\theta_{MV}-\theta}{\theta/\sqrt{n}}
    \approx N(0,1).
\]

Como $\theta$ é desconhecido, podemos utilizar o valor de Máxima Verossimilhança $\hat\theta_{MV}$ que é um parâmetro consistente e se aproxima de $\theta$
quando n é grande. Então substituímos $\theta$ por $\hat\theta_{MV}$ no denominador:
\[
    \frac{\hat\theta_{MV}-\theta}{\hat\theta_{MV}/\sqrt{n}}
    \approx N(0,1).
\]

Para um nível de confiança $1-\alpha$, o intervalo de confiança da Normal Padrão \(N(0, 1)\) é:
\[
    P\!\left( -z_{1-\alpha/2}
    \le
    \frac{\hat\theta_{MV}-\theta}{\hat\theta_{MV}/\sqrt{n}}
    \le
    z_{1-\alpha/2}
    \right)\approx 1-\alpha.
\]

\[
    P\!\left(
    -z_{1-\alpha/2}\,\frac{\hat{\theta}_{MV}}{\sqrt{n}}
    \;\le\;
    \hat{\theta}_{MV}-\theta
    \;\le\;
    z_{1-\alpha/2}\,\frac{\hat{\theta}_{MV}}{\sqrt{n}}
    \right)
    \approx 1-\alpha.
\]

\[
    P\!\left(
    -z_{1-\alpha/2}\,\frac{\hat{\theta}_{MV}}{\sqrt{n}}
    -
    \hat{\theta}_{MV}
    \;\le\;
    -\theta
    \;\le\;
    z_{1-\alpha/2}\,\frac{\hat{\theta}_{MV}}{\sqrt{n}}
    -
    \hat{\theta}_{MV}
    \right)
    \approx 1-\alpha.
\]

\[
    P\!\left(
    \hat{\theta}_{MV}
    -
    z_{1-\alpha/2}\,\frac{\hat{\theta}_{MV}}{\sqrt{n}}
    \;\le\;
    \theta
    \;\le\;
    \hat{\theta}_{MV}
    +
    z_{1-\alpha/2}\,\frac{\hat{\theta}_{MV}}{\sqrt{n}}
    \right)
    \approx 1-\alpha.
\]

\[
    P\!\left(
    \hat{\theta}_{MV}\!\left(1-\frac{z_{1-\alpha/2}}{\sqrt{n}}\right)
    \;\le\;
    \theta
    \;\le\;
    \hat{\theta}_{MV}\!\left(1+\frac{z_{1-\alpha/2}}{\sqrt{n}}\right)
    \right)
    \approx 1-\alpha.
\]

\[
    \boxed{
        \theta \in
        \left[
            \hat{\theta}_{MV}\!\left(1-\frac{z_{1-\alpha/2}}{\sqrt{n}}\right),
            \;\;
            \hat{\theta}_{MV}\!\left(1+\frac{z_{1-\alpha/2}}{\sqrt{n}}\right)
            \right]
    }
\]


É útil nomear os limites inferior e superior para referência:
\[
    L_\theta =
    \hat\theta_{MV}\!\left(1-\frac{z_{1-\alpha/2}}{\sqrt{n}}\right),
    \qquad
    U_\theta =
    \hat\theta_{MV}\!\left(1+\frac{z_{1-\alpha/2}}{\sqrt{n}}\right).
\]
%%%%%%%%%%%%%<
\subsubsection*{Cálculo do intervalo aproximado para o Item (a):  $g(\theta)=P_\theta(Z>1)$}

Para a Exponencial, temos:
\[
    g(\theta)=P_\theta(Z>1)
    =\int_{1}^{\infty}\theta e^{-\theta z}\,dz
    = e^{-\theta}.
\]

A função $g(\theta)=e^{-\theta}$ é estritamente decrescente em $\theta$. Para $L_\theta \le \theta \le U_\theta$,
como $g$ é decrescente,

%%%
\[
    g(L_\theta) \;\ge\; g(\theta) \;\ge\; g(U_\theta).
\]

Substituímos $g(x) = e^{-x}$:
\[
    e^{-L_\theta} \;\ge\; e^{-\theta} \;\ge\; e^{-U_\theta} \iff
    e^{-U_\theta} \;\le\; g(\theta) \;\le\; e^{-L_\theta}.
\]

Logo, o IC aproximado para $g(\theta)$ é:
\[
    \boxed{
    g(\theta)\in
    \bigl[e^{-U_\theta},\,e^{-L_\theta}\bigr].}
\]

Para os dados amostrados:
\[
    (0.2,\; 0.6,\; 0.3,\; 0.2,\; 0.8,\; 0.12).
\]

\[
    n=6, \qquad
    S=\sum z_i = 2.22, \qquad
    \bar Z = \frac{S}{6}=0.37.
\]

\[
    \hat\theta_{MV}=\frac{1}{\bar Z}=\frac{1}{0.37}\approx 2.703.
\]

Com $z_{0.975}=1.96$ e $n=6$:
\[
    \frac{z_{0.975}}{\sqrt{n}}
    = \frac{1.96}{\sqrt{6}}
    \approx 0.800.
\]

\[
    L_\theta
    =2.703(1-0.800)
    \approx 0.541,
    \qquad
    U_\theta
    =2.703(1+0.800)
    \approx 4.864.
\]

Portanto, o IC aproximado de 95\% para $\theta$ é:
\[
    \theta\in[0.541,\;4.864]
\]

\[
    g_{\min}=e^{-U_\theta}=e^{-4.864}\approx 0.0077,
    \qquad
    g_{\max}=e^{-L_\theta}=e^{-0.541}\approx 0.583.
\]

\[
    \boxed{
        g(\theta)=P_\theta(Z>1)\in[0.0077,\;0.583].
    }
\]







\subsubsection*{Cálculo do intervalo aproximado para o Item (b): $g(\theta)=P_\theta(0{,}1<Z<1)$}

Para a Exponencial, temos
\[
    f(z;\theta)=\theta e^{-\theta z},\qquad z>0,\ \theta>0.
\]

Então
\[
    g(\theta)=P_\theta(0{,}1<Z<1)
    =\int_{0.1}^{1}\theta e^{-\theta z}\,dz
    =\Bigl[-e^{-\theta z}\Bigr]_{z=0.1}^{z=1}
    =e^{-0.1\theta}-e^{-\theta}.
\]
Do item (a), usando a teoria assintótica do EMV e a Informação de Fisher
(obtendo $\widehat\theta_{MV}\approx N\!\left(\theta,\theta^2/n\right)$),
para um nível de confiança $1-\alpha$ temos
\[
    P\!\left(
    -z_{1-\alpha/2}
    \;\le\;
    \frac{\widehat\theta_{MV}-\theta}{\widehat\theta_{MV}/\sqrt{n}}
    \;\le\;
    z_{1-\alpha/2}
    \right)\approx 1-\alpha.
\]

Manipulando a inequação, obtemos o IC aproximado
\[
    \theta\in\biggl[
        \widehat\theta_{MV}\Bigl(1-\frac{z_{1-\alpha/2}}{\sqrt{n}}\Bigr),
        \;
        \widehat\theta_{MV}\Bigl(1+\frac{z_{1-\alpha/2}}{\sqrt{n}}\Bigr)
        \biggr]
    =: [L_\theta,U_\theta].
\]

\paragraph{Análise de $g(\theta)$}. Derivando,
\[
    g'(\theta)
    = -0{,}1\,e^{-0.1\theta}+e^{-\theta}.
\]

O ponto crítico é dado por $g'(\theta^\ast)=0$:
\[
    -0{,}1\,e^{-0.1\theta^\ast}+e^{-\theta^\ast}=0
    \iff;
    e^{-\theta^\ast}=0{,}1\,e^{-0.1\theta^\ast}
    \iff;
    e^{-0.9\theta^\ast}=0{,}1
    \iff\;
    \theta^\ast=\frac{\log 10}{0.9}.
\]

Logo, $g(\theta)$ cresce em $0\le\theta\le\theta^\ast$ e decresce em
$\theta\ge\theta^\ast$ (único máximo em $\theta^\ast$).

\paragraph{Intervalo para $g(\theta)$ a partir do IC de $\theta$}
\[\]
Dado o IC $[L_\theta,U_\theta]$ para $\theta$, o intervalo correspondente para
$g(\theta)$ é o intervalo que contém todos os valores
\[
    \{g(\theta):\theta\in[L_\theta,U_\theta]\}.
\]

Como $g$ é crescente até $\theta^\ast$ e decrescente depois, se
$\theta^\ast\in[L_\theta,U_\theta]$ temos
\[
    g_{\min} = \min\{g(L_\theta),g(U_\theta)\},
    \qquad
    g_{\max} = g(\theta^\ast),
\]
e, portanto,
\[
    g(\theta)\in[g_{\min},g_{\max}].
\]

Os dados observados são $(0{,}2,\ 0{,}6,\ 0{,}3,\ 0{,}2,\ 0{,}8,\ 0{,}12) $, para os quais já havíamos obtido, no item (a):
\[
    n=6,\qquad
    \widehat\theta_{MV}=\frac{1}{\bar Z}\approx 2{,}703,
\]
e, com $z_{0.975}=1{,}96$,
\[
    L_\theta=\widehat\theta_{MV}\Bigl(1-\frac{z_{0.975}}{\sqrt{n}}\Bigr)
    \approx 0{,}541,\qquad
    U_\theta=\widehat\theta_{MV}\Bigl(1+\frac{z_{0.975}}{\sqrt{n}}\Bigr)
    \approx 4{,}864.
\]

O ponto de máximo é
\[
    \theta^\ast=\frac{\log 10}{0.9}\approx 2{,}558,
\]
que de fato pertence ao intervalo $[L_\theta,U_\theta]$.

Calculando:
\[
    g(L_\theta)=e^{-0.1 L_\theta}-e^{-L_\theta}
    \approx 0{,}365,
\]
\[
    g(U_\theta)=e^{-0.1 U_\theta}-e^{-U_\theta}
    \approx 0{,}607,
\]
\[
    g(\theta^\ast)=e^{-0.1\theta^\ast}-e^{-\theta^\ast}
    \approx 0{,}697.
\]

Logo,
\[
    g_{\min}=\min\{g(L_\theta),g(U_\theta)\}\approx 0{,}365,\qquad
    g_{\max}=g(\theta^\ast)\approx 0{,}697.
\]

Portanto, o \textbf{intervalo de confiança aproximado de 95\%} para
\[
    g(\theta)=P_\theta(0{,}1<Z<1)
\]
é
\[
    \boxed{
        g(\theta)=P_\theta(0{,}1<Z<1)\in[0{,}365,\ 0{,}697].
    }
\]









\subsubsection*{Cálculo do intervalo aproximado para o Item (c): $g(\theta) = \mathrm{Var}\theta(Z)$}
\[\]
Para $Z \sim \mathrm{Exp}(\theta)$ com $\theta>0$, sabe-se que
\[
    g(\theta) = \mathrm{Var}\theta(Z) = \frac{1}{\theta^2}.
\]

Na letra (d) queremos um IC aproximado de 95\% para $g(\theta)$ usando os
dados
\[
    (0{,}2,\;0{,}6,\;0{,}3,\;0{,}2,\;0{,}8,\;0{,}12).
\]

Primeiro, relembramos o IC aproximado para $\theta$ obtido pela
assintótica Normal do EMV.

A média amostral é
\[
    \bar Z = \frac{1}{6}\sum_{i=1}^6 z_i = \frac{2{,}22}{6} \approx 0{,}37,
\]
e o EMV de $\theta$ é
\[
    \hat\theta_{MV} = \frac{1}{\bar Z} \approx \frac{1}{0{,}37} \approx 2{,}703.
\]

Pela teoria assintótica do EMV,
\[
    \hat\theta_{MV} \approx N\!\left(\theta,\;\frac{\theta^2}{n}\right),
\]
e, substituindo $\theta$ por $\hat\theta_{MV}$ no desvio-padrão,
obtemos o IC aproximado de 95\% para $\theta$:
\[
    P\!\left(
    -z_{0{,}975}
    \le
    \frac{\hat\theta_{MV} - \theta}{\hat\theta_{MV}/\sqrt{n}}
    \le
    z_{0{,}975}
    \right)
    \approx 0{,}95,
\]
o que é equivalente a
\[
    \theta \in
    \Bigl[
        \hat\theta_{MV}\!\left(1 - \frac{z_{0{,}975}}{\sqrt{n}}\right),
        \;
        \hat\theta_{MV}\!\left(1 + \frac{z_{0{,}975}}{\sqrt{n}}\right)
        \Bigr].
\]

Com $z_{0{,}975} = 1{,}96$ e $n = 6$,
\[
    \frac{z_{0{,}975}}{\sqrt{n}}
    =
    \frac{1{,}96}{\sqrt{6}}
    \approx 0{,}800,
\]
logo
\[
    L_\theta = \hat\theta_{MV}(1 - 0{,}800) \approx 2{,}703 \times 0{,}200 \approx 0{,}541,
\]
\[
    U_\theta = \hat\theta_{MV}(1 + 0{,}800) \approx 2{,}703 \times 1{,}800 \approx 4{,}864.
\]

Portanto, o IC aproximado de 95\% para $\theta$ é
\[
    \theta \in [\,0{,}541,\;4{,}864\,].
\]

\medskip

Agora transformamos esse intervalo para $g(\theta)=\mathrm{Var}\theta(Z)=1/\theta^2$. Analisando $g(\theta)$:
\[
    g(\theta) = \frac{1}{\theta^2}, \qquad \theta>0,
\]
é estritamente decrescente em $\theta$. Assim, se
\[
    L_\theta \le \theta \le U_\theta,
\]
então, aplicando $g$ e invertendo a ordem das desigualdades,
\[
    g(U_\theta) \le g(\theta) \le g(L_\theta),
\]
isto é,
\[
    \frac{1}{U_\theta^2} \le \mathrm{Var}\theta(Z) \le \frac{1}{L_\theta^2}.
\]

Logo, um IC aproximado de 95\% para $g(\theta)=\mathrm{Var}\theta(Z)$ é
\[
    g(\theta) = \mathrm{Var}\theta(Z) \in
    \left[
        \frac{1}{U_\theta^2},\;
        \frac{1}{L_\theta^2}
        \right].
\]

Substituindo os valores numéricos $L_\theta \approx 0{,}541$ e
$U_\theta \approx 4{,}864$,
\[
    \frac{1}{U_\theta^2} \approx \frac{1}{4{,}864^2} \approx 0{,}042,
    \qquad
    \frac{1}{L_\theta^2} \approx \frac{1}{0{,}541^2} \approx 3{,}42.
\]

Portanto, o intervalo de confiança aproximado de 95\% para a variância é
\[
    \boxed{
    \mathrm{Var}\theta(Z) \in [\,0{,}042,\;3{,}42\,].}
\]


\paragraph{(e) Teste de confiança do IC's via simulação Monte Carlo}

\begin{itemize}

    \item[(a)] No experimento de Monte Carlo associado ao Listing~\ref{lst:a},
          com $M=1000$ simulações, a taxa de cobertura obtida foi $0.962$.
          Assim, o métod utilizado para encontrar o intervalo aproximado para $g(\theta)=e^{-\theta}$ cobriu o valor
          verdadeiro em $96.2\%$ das repetições, desempenho compatível com o nível
          nominal de $95\%$ mesmo para $n=6$.

    \item[(b)] Para o intervalo construído no Listing~\ref{lst:b},
          a cobertura obtida foi $0.981$.
          O intervalo aproximado para $g(\theta)=P_\theta(0.1<Z<1)$ apresentou
          desempenho compatível com a cobertura de $95\%$, mesmo para amostra pequena.

    \item[(c)] No experimento correspondente ao Listing~\ref{lst:c},
          referente a $g(\theta)=\mathrm{Var}_\theta(Z)=1/\theta^{2}$,
          a taxa de cobertura obtida foi $0.962$.
          O método aproximado forneceu um intervalo com desempenho acima
          do nível nominal de $95\%$, mesmo sob amostra pequena.

\end{itemize}

% \begin{itemize}
%     \item[(a)] O experimento de Monte Carlo com $M = 1000$ repetições produziu uma
%           estimativa de cobertura igual a $0.962$. Ou seja, em
%           $96.2\%$ das simulações, o intervalo de confiança
%           aproximado para $g(\theta)=e^{-\theta}$ conteve o verdadeiro valor
%           $g(\theta_0)$. Como o nível
%           nominal do IC é de $95\%$, o resultado está ótimo,
%           indicando que a aproximação Normal para o estimador de máxima
%           verossimilhança funciona bem mesmo com uma amostra pequena ($n=6$),
%           fornecendo intervalos com cobertura adequada.
%     \item[(b)] O experimento de Monte Carlo retornou uma taxa de cobertura estimada de
%           $\widehat{C} = 0.981$.
%           Esse valor está muito próximo do nível nominal de $95\%$, indicando que o
%           intervalo de confiança aproximado obtido pelo método assintótico apresenta
%           excelente desempenho para o funcional $g(\theta)=P_{\theta}(0.1<Z<1)$ mesmo com
%           amostras pequenas ($n=6$).
%           A pequena supercobertura observada (98.1\%) é esperada, pois o intervalo para
%           $g(\theta)$ é construído a partir do intervalo para $\theta$ via uma função não
%           monótona, o que tende a torná-lo ligeiramente mais conservador.
%     \item[(c)]Para o item (c), em que $g(\theta) = \mathrm{Var}_\theta(Z) = 1/\theta^{2}$, a simulação de Monte Carlo
%           produziu uma taxa de cobertura empírica igual a $0.962$ para o intervalo de confiança aproximado
%           obtido via método delta. Esse valor está muito próximo do nível nominal de $95\%$, indicando que,
%           apesar de o método delta ser uma aproximação de primeira ordem e de a amostra ser relativamente pequena
%           ($n = 6$), a linearização utilizada para $g(\theta)$ fornece um intervalo suficientemente correto.
%           Em particular, mesmo se tratando de uma transformação fortemente não linear em $\theta$, o uso de
%           $\widehat{\theta}_{MV}$ na avaliação das derivadas e da variância assintótica melhora a performance do
%           estimador, resultando em um intervalo cuja cobertura efetiva é ligeiramente superior ao nível desejado,
%           mas ainda dentro da variação esperada por erro Monte Carlo.
% \end{itemize}
% \paragraph{(a) \(g(\theta)=P_\theta(Z>1)\).}

% \begin{enumerate}
%   \item Pela fórmula da cauda,
%   \[
%   g(\theta)=P_\theta(Z>1)=e^{-\theta\cdot 1}=e^{-\theta}.
%   \]
%   \item Pela \textbf{invariância do EMV},
%   \[
%   \widehat g_{MV}=g(\widehat\theta_{MV})=e^{-\widehat\theta_{MV}}.
%   \]
%   \item Usando \(\widehat\theta_{MV}=\dfrac{1}{\overline Z}\),
%   \[
%   \boxed{\;\widehat g_{(a)}=e^{-\widehat\theta_{MV}}
%         =\exp\!\Big(-\frac{1}{\overline Z}\Big).\;}
%   \]
% \end{enumerate}

% \bigskip
% \paragraph{(b) \(g(\theta)=P_\theta(0.1<Z<1)\).}

% \begin{enumerate}
%   \item Para \(0<a<b\), utilizando a expressão para função de distribuição acumulada já calculada,
%   \[
%   P_\theta(a<Z<b)=F(b)-F(a)=(1-e^{-\theta b})-(1-e^{-\theta a})
%                  =e^{-\theta a}-e^{-\theta b}.
%   \]
%   \item Com \(a=0.1\) e \(b=1\),
%   \[
%   g(\theta)=e^{-0.1\,\theta}-e^{-\theta}.
%   \]
%   \item Pela invariância,
%   \[
%   \;\widehat g_{(b)}=e^{-0.1\,\widehat\theta_{MV}}-e^{-\widehat\theta_{MV}}
%         =\exp\!\Big(-\frac{0.1}{\overline Z}\Big)-\exp\!\Big(-\frac{1}{\overline Z}\Big).\;
%   \]
%   \[
%   \boxed{\;\widehat g_{(b)}=
%         \exp\!\Big(-\frac{0.1}{\overline Z}\Big)-\exp\!\Big(-\frac{1}{\overline Z}\Big).\;}
%   \]
% \end{enumerate}

% \bigskip
% \paragraph{(c) \(g(\theta)=\mathrm{Var}_\theta(Z)\).}

% \begin{enumerate}
%   \item Para \(Z\sim\mathrm{Exp}(\theta)\), \(E(Z)=\dfrac{1}{\theta}\) e
%         \(E(Z^2)=\displaystyle\int_0^\infty z^2\theta e^{-\theta z}dz
%                  =\frac{2}{\theta^2}\).
%         Assim,
%         \[
%         \mathrm{Var}_\theta(Z)=E(Z^2)-E(Z)^2=\frac{2}{\theta^2}-\frac{1}{\theta^2}
%         =\frac{1}{\theta^2}.
%         \]
%   \item Logo \(g(\theta)=\theta^{-2}\) e, por invariância,
%         \[
%         \widehat g_{MV}=g(\widehat\theta_{MV})=\frac{1}{\widehat\theta_{MV}^{\,2}}.
%         \]
%   \item Como \(\widehat\theta_{MV}=1/\overline Z\),
%         \[
%         \boxed{\;\widehat g_{(c)}=\frac{1}{(1/\overline Z)^2}=\overline Z^{\,2}. \;}
%         \]
% \end{enumerate}


% \bigskip
% \textbf{(d) ICs aproximados de 95\% para $g(\theta)$ (usando o método delta).}
% Para a Exponencial, a informação de Fisher é $I(\theta)=\tfrac{n}{\theta^2}$,
% de modo que
% \[
% \widehat\theta_{MV}\ \dot\sim\ N\!\left(\theta,\ \frac{\theta^2}{n}\right).
% \]
% Pelo método delta, para $g$ diferenciável:
% \[
% \widehat g\ \dot\sim\ N\!\left(g(\theta),\ \frac{\theta^2}{n}\,[g'(\theta)]^2\right),
% \quad\text{e usamos } \theta\leftarrow\widehat\theta_{MV}.
% \]
% Assim:

% \smallskip
% \begin{itemize}
% \item[(a)] $g(\theta)=e^{-\theta}$, $g'(\theta)=-e^{-\theta}$. Então
% \[
% \widehat{\mathrm{Var}}(\widehat g_{(a)})
% =\frac{\widehat\theta_{MV}^2}{n}\,e^{-2\widehat\theta_{MV}},
% \qquad
% \text{IC}_{95\%}:\ \widehat g_{(a)}\ \pm\ 1.96\,
% \sqrt{\frac{\widehat\theta_{MV}^2}{n}\,e^{-2\widehat\theta_{MV}}}.
% \]
% \item[(b)] $g(\theta)=e^{-0.1\theta}-e^{-\theta}$,
% \(
% g'(\theta)=-0.1\,e^{-0.1\theta}+e^{-\theta}.
% \)
% Então
% \[
% \widehat{\mathrm{Var}}(\widehat g_{(b)})
% =\frac{\widehat\theta_{MV}^2}{n}\,\bigl[-0.1\,e^{-0.1\widehat\theta_{MV}}+e^{-\widehat\theta_{MV}}\bigr]^2,
% \]
% \[
% \text{IC}_{95\%}:\ \widehat g_{(b)}\ \pm\ 1.96\,
% \sqrt{\frac{\widehat\theta_{MV}^2}{n}\,\bigl[-0.1\,e^{-0.1\widehat\theta_{MV}}+e^{-\widehat\theta_{MV}}\bigr]^2}.
% \]
% \item[(c)] $g(\theta)=1/\theta^2$, $g'(\theta)=-2/\theta^3$. Então
% \[
% \widehat{\mathrm{Var}}(\widehat g_{(c)})
% =\frac{4}{n\,\widehat\theta_{MV}^{\,4}},
% \qquad
% \text{IC}_{95\%}:\ \widehat g_{(c)}\ \pm\ 1.96\,\sqrt{\frac{4}{n\,\widehat\theta_{MV}^{\,4}}}.
% \]
% \end{itemize}

% \medskip
% \textbf{Aplicando aos dados} $(0.2,0.6,0.3,0.2,0.8,0.12)$:
% \[
% n=6,\quad \textstyle\sum z_i=2.22,\quad \overline Z=0.37,\quad
% \widehat\theta_{MV}=\frac{n}{\sum z_i}=\frac{6}{2.22}\approx 2.7027.
% \]
% \emph{Estimativas plug-in:}
% \[
% \widehat g_{(a)}=e^{-\widehat\theta_{MV}}\approx 0.0668,\qquad
% \widehat g_{(b)}=e^{-0.1\widehat\theta_{MV}}-e^{-\widehat\theta_{MV}}\approx 0.6963,\qquad
% \widehat g_{(c)}=\overline Z^{\,2}=0.1369.
% \]
% \emph{ICs (delta, 95\%):}
% \[
% \text{(a)}\ \ [0,\ 0.211]\ \ (\text{truncado a }[0,1]),
% \qquad
% \text{(b)}\ \ [0.676,\ 0.717],
% \qquad
% \text{(c)}\ \ [0,\ 0.356]\ \ (\text{truncado a }[0,\infty)).
% \]
% \textit{Obs.:} Com $n=6$ o delta pode produzir limites fora do espaço paramétrico; é
% padrão truncar aos limites naturais.

% \bigskip
% \textbf{(e) Cobertura por Monte Carlo (plano de simulação).}
% Para verificar a cobertura empírica dos ICs acima:
% \begin{enumerate}
% \item Fixe um valor de $\theta$ (por ex., $\theta=\widehat\theta_{MV}=2.7027$) e tamanhos $n\in\{6,10,20,30,50\}$.
% \item Para cada par $(\theta,n)$, repita $B$ vezes (ex.: $B=10{,}000$):
% \begin{enumerate}
% \item Gere $Z_1,\ldots,Z_n\overset{iid}\sim \mathrm{Exp}(\theta)$.
% \item Calcule $\widehat\theta_{MV}$, as estimativas $\widehat g$ e os ICs (delta) de (a)--(c).
% \item Registre se o verdadeiro $g(\theta)$ caiu dentro do IC.
% \end{enumerate}
% \item Estime a cobertura como a frequência relativa de acertos. Compare com 95\%.
% \item Se a cobertura ficar abaixo de 95\%, aumente $n$ até estabilizar próximo de 95\%.
% \end{enumerate}
% \textit{Expectativa:} Para $n=6$, (a) e (c) tendem a cobertura abaixo de 95\% (assimetria/limites fora do espaço).
% Cobertura melhora sensivelmente para $n\gtrsim 30$. 





% Então vamos encontrar o intervalo de confiança exato para $\theta$ usando $\chi^2$.

% Da propriedade
% \[
%     2\theta S \sim \chi^2_{2n},
% \]
% obtemos, para nível de confiança $1-\alpha$ (aqui $0{,}95$):
% \[
%     P\!\left( \chi^2_{2n,\alpha/2} \le 2\theta S \le \chi^2_{2n,1-\alpha/2} \right)=1-\alpha.
% \]

% Dividindo tudo por $2S>0$:
% \[
%     P\!\left(
%     \frac{\chi^2_{2n,\alpha/2}}{2S}
%     \le \theta \le
%     \frac{\chi^2_{2n,1-\alpha/2}}{2S}
%     \right)
%     =1-\alpha.
% \]

% Logo, o intervalo de confiança de 95\% para $\theta$ é
% \[
%     \boxed{
%     \theta \in
%     \left[
%     \frac{\chi^2_{2n,0.025}}{2S},\
%     \frac{\chi^2_{2n,0.975}}{2S}
%     \right].
%     }
% \]

% \bigskip

% \subsection*{3. Relacionando $\theta$ e $g(\theta)$}

% Para a Exponencial,
% \[
%     g(\theta)=P_\theta(Z>1)=\int_1^\infty \theta e^{-\theta z}dz = e^{-\theta}.
% \]

% Note que $g(\theta)=e^{-\theta}$ é \textbf{monótona decrescente} em $\theta$.

% Se $\theta \in [L_\theta,U_\theta]$, então:
% \[
%     L_\theta \le \theta \le U_\theta
%     \quad\Longrightarrow\quad
%     e^{-U_\theta} \le e^{-\theta} \le e^{-L_\theta}.
% \]

% Logo, o IC de 95\% para $g(\theta)$ é:
% \[
%     \boxed{
%         g(\theta)\in
%         \left[ e^{-U_\theta}, \ e^{-L_\theta} \right].
%     }
% \]
% onde
% \[
%     L_\theta=\frac{\chi^2_{2n,0.025}}{2S},
%     \qquad
%     U_\theta=\frac{\chi^2_{2n,0.975}}{2S}.
% \]

% \bigskip

% \subsection*{4. Aplicando aos dados observados}

% Os dados fornecidos são:
% \[
%     (0.2,\ 0.6,\ 0.3,\ 0.2,\ 0.8,\ 0.12),
% \]
% logo
% \[
%     n=6,\qquad
%     S=\sum_{i=1}^6 z_i = 2.22.
% \]

% Para $1-\alpha=0.95$ e $2n=12$ graus de liberdade:

% \[
%     \chi^2_{12,0.025}\approx 4.404,
%     \qquad
%     \chi^2_{12,0.975}\approx 23.337.
% \]

% Então,
% \[
%     L_\theta=\frac{4.404}{2\cdot 2.22}\approx 0.992,
%     \qquad
%     U_\theta=\frac{23.337}{2\cdot 2.22}\approx 5.256.
% \]

% O intervalo de 95\% para $\theta$ é:
% \[
%     \theta\in [\,0.992,\ 5.256\,].
% \]

% Transformando para $g(\theta)=e^{-\theta}$:
% \[
%     g_{\min}=e^{-U_\theta}\approx e^{-5.256}\approx 0.0052,
% \]
% \[
%     g_{\max}=e^{-L_\theta}\approx e^{-0.992}\approx 0.371.
% \]

% \bigskip

% \subsection*{5. Resultado final}

% \[
%     \boxed{
%         g(\theta)=P_\theta(Z>1)\in [0.0052,\ 0.371].
%     }
% \]

% Este é o intervalo de confiança de 95\% solicitado.

