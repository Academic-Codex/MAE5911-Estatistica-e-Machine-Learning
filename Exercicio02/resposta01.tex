O estimador via função de máxima verossimilhança foi proposto por Fisher, que demonstrou a superioridade do deste método referente a outros métodos estimadores, como o método de momentos. 
Este estimador é utilizado sobretudo quando a informação da distribuição de probabilidade do modelo é conhecida. 
Ela tem propriedades como eficiência assintótica, consistência, distribuição normal e invariancia [Notas de aula pg. 60]. 
O estimador de máxima verossimilhança representa uma estimativa para o valor do parâmetro $\theta$ que torna os dados observados o mais plausível possível. 
\\[0.5em]
Devido a propriedade de invariancia do EMV, basta encontrarmos EMV para a letra (a) e depois calcular a letra (b) utilizando este estimador como parâmetro.


Seja \( (Z_1, \dots, Z_n) \) a amostra aleatória de 
\[
Z_i \sim \mathrm{Bernoulli}(\theta), \quad \theta \in (0,1).
\]

A função de verossimilhança, que é a função de densidade de probabilidade conjunta do modelo, é dada por
\[
L(\theta; z_1, \dots, z_n)
= \prod_{i=1}^n \theta^{z_i}(1-\theta)^{1-z_i}.
\]

Para encontrar o estimador de máxima verossimilhança, precisamos maximizar \( L(\theta) \) em relação a \( \theta \). Mas como esta função se trata de um produtório,
é mais fácil maximizar a função log-verossimilhança, que por ser monotonicamente crescente, preserva o valor de theta no ponto máximo \( L(\theta) \).


\text{Tomando o logaritmo natural em ambos os lados:}

\[
\ell(\theta)
= \log L(\theta; z_1, \ldots, z_n)
= \log\!\left(\prod_{i=1}^{n} \theta^{z_i}(1-\theta)^{1-z_i}\right).
\]


\text{Sabendo que } 
\(
\log(ab) = \log a + \log b \text{ e que } 
\log\!\left(\prod_i a_i\right) = \sum_i \log a_i, \text{ temos:}
\)

\[
\ell(\theta)
= \sum_{i=1}^{n} \log\!\big(\theta^{z_i}(1-\theta)^{1-z_i}\big).
\]

\text{Aplicando novamente a propriedade do logaritmo de um produto: }

\[
\ell(\theta)
= \sum_{i=1}^{n} \big[\log(\theta^{z_i}) + \log((1-\theta)^{1-z_i})\big].
\]

\(
\text{Sabendo que } \log(a^b) = b\log a, \text{ obtemos:}
\)

\[
\ell(\theta)
= \sum_{i=1}^{n} \big[z_i \log \theta + (1 - z_i)\log(1-\theta)\big].
\]

\text{Por fim, separando as somas:}

\[
\ell(\theta)
= \left(\sum_{i=1}^{n} z_i\right)\log \theta
+ \left(\sum_{i=1}^{n}(1-z_i)\right)\log(1-\theta).
\]

A log-verossimilhança correspondente é
\[
\boxed{\ell(\theta) 
= \sum_{i=1}^n \big[z_i \log\theta + (1-z_i)\log(1-\theta)\big].}
\]

Para derivar em relação a \(\theta\), sabemos que 
\(\dfrac{d}{d\theta}\log\theta=\dfrac1\theta\) e 
\(\dfrac{d}{d\theta}\log(1-\theta)= -\dfrac1{1-\theta}\), obtemos,
termo a termo:

\[
\frac{d}{d\theta}\Big[z_i\log\theta\Big]
= z_i\,\frac1\theta
\qquad\text{e}\qquad
\frac{d}{d\theta}\Big[(1-z_i)\log(1-\theta)\Big]
= (1-z_i)\Big(-\frac1{1-\theta}\Big)
= -\,\frac{1-z_i}{1-\theta}.
\]
Logo,
\[
\ell'(\theta)
=\sum_{i=1}^n\left(\frac{z_i}{\theta}-\frac{1-z_i}{1-\theta}\right)
= \frac{\sum_{i=1}^n z_i}{\theta} - \frac{\sum_{i=1}^n(1-z_i)}{1-\theta}
= \frac{\sum_i z_i}{\theta} - \frac{n-\sum_i z_i}{1-\theta}.
\]

\text{Igualando a zero para encontrar o} \textbf{ponto crítico.}
\[
\ell'(\theta)=0
\;\Longleftrightarrow\;
\frac{\sum_i z_i}{\theta}
= \frac{n-\sum_i z_i}{1-\theta}
\;\Longleftrightarrow\;
(1-\theta)\sum_i z_i=\theta\,(n-\sum_i z_i).
\]
Expandindo e rearranjando:
\[
\sum_i z_i - \theta\sum_i z_i = \theta n - \theta\sum_i z_i
\;\Longleftrightarrow\;
\sum_i z_i = \theta n
\;\Longleftrightarrow\;
\widehat\theta_{MV}=\frac1n\sum_{i=1}^n z_i=\overline Z.
\]


Obtivemos o estimador de máxima verossimilhança para a probabilidade de sucesso \(\theta\):
\[
\boxed{\hat{\theta}_{MV} = \bar{Z} = \frac{1}{n}\sum_{i=1}^n Z_i.}
\]

O teste de hipótese, mede o quão improvável seria observar $\hat{\theta}_{MV}$ se a hipótese nula fosse verdadeira. O valor-p é esta medida de improbabilidade.
\\[1em]
Em condições de regularidade, o valor-$p$ segue uma distribuição uniforme em $(0,1)$.
Isso significa que, se o seu valor é muito pequeno, por exemplo $p \leq 0{,}01$,
então o resultado observado é um evento raro sob a hipótese nula $H_0$,
ou, alternativamente, que a hipótese nula está incorreta.
Nessa situação, existem evidências para rejeitar $H_0$.


---

\paragraph{(a) \(g(\theta)=P_\theta(Z=0)\)}

\begin{enumerate}
  \item Seja \(Z \sim \mathrm{Bernoulli}(\theta)\), temos:
  \[
  P_\theta(Z=z)=\theta^z(1-\theta)^{1-z}, \quad z \in \{0,1\}.
  \]

  \item Substituindo \(z=0\):
  \[
  P_\theta(Z=0)=\theta^0(1-\theta)^{1-0}=1-\theta.
  \]

  \item Portanto,
  \[
  g(\theta)=1-\theta.
  \]

  \item Pela \textbf{invariância do EMV}, temos:
  \[
  \widehat g_{MV}=g(\widehat\theta_{MV})=1-\widehat\theta_{MV}.
  \]

  \item E como \(\widehat\theta_{MV}=\overline Z\), obtemos:
  \[
  \boxed{\widehat g_{MV}=1-\overline Z.}
  \]
\end{enumerate}


---

\paragraph{(b) \(g(\theta)=\mathrm{Var}_\theta(Z)\)}

\begin{enumerate}
  \item Para uma Bernoulli, a variância é dada por:
  \[
  \mathrm{Var}(Z)=E(Z^2)-E(Z)^2.
  \]

  \item Como \(E(Z)=\theta\) e \(Z^2=Z\) (pois \(Z\in\{0,1\}\)), então:
  \[
  \mathrm{Var}_\theta(Z)=\theta-\theta^2=\theta(1-\theta).
  \]

  \item Portanto,
  \[
  g(\theta)=\theta(1-\theta).
  \]

  \item Pela \textbf{invariância do EMV}:
  \[
  \widehat g_{MV}=g(\widehat\theta_{MV})
  =\widehat\theta_{MV}(1-\widehat\theta_{MV}).
  \]

  \item Como \(\widehat\theta_{MV}=\overline Z\), segue:
  \[
  \boxed{\widehat g_{MV}=\overline Z(1-\overline Z).}
  \]
\end{enumerate}


---

(c) Sejam os dados observados: \( (0, 0, 1, 0, 0, 1) \)

Temos \( n = 6 \) e \( \sum z_i = 2 \), portanto
\[
\hat{\theta}_{MV} = \bar{Z} = \frac{2}{6} = \frac{1}{3} \approx 0.3333.
\]
Assim:
\[
\widehat{P(Z=0)} = 1 - \hat{\theta}_{MV} = \frac{2}{3} \approx 0.6667,
\]
\[
\widehat{\mathrm{Var}}(Z) = \hat{\theta}_{MV}(1 - \hat{\theta}_{MV})
= \frac{1}{3} \cdot \frac{2}{3} = \frac{2}{9} \approx 0.2222.
\]

---

(d) Teste de hipótese \( H_0: \theta = 0.1 \)

Queremos verificar se temos evidência a partir dos dados observados para rejeitar a hipótese nula 
de que a probabilidade de sucesso é $\theta = 0.1$.

Sabemos que, sob $H_0$, a estatística
\[
X = \sum_{i=1}^{n} Z_i
\]
segue uma distribuição $\text{Binomial}(n, \theta)$.

Com $n = 6$ e $x_{\text{obs}} = 2$ sucessos observados, temos:
\[
X \sim \text{Binomial}(6, 0.1).
\]

---
 
O valor-p é a probabilidade de observar um valor da estatística $T(Z_n)$ 
\textit{tão ou mais extremo quanto o observado}, assumindo que $H_0$ é verdadeira:
\[
\boxed{
\text{valor-}p(H_0, \mathbf{z}_n)
= \sup_{\theta \in \Theta_0}
P^{(n)}_{\theta}\!\big(
T_{H_0}(\mathbf{Z}_n)
\ge
T_{H_0}(\mathbf{z}_n)
\big).
}
\]
No contexto binomial, a estatística de teste é o número de sucessos $X$. Vamos avaliar a probabilidade de eventos
com parâmetro de sucesso a partir da amostra observada até eventos mais extremos uma vez que a amostra observada já está acima do esperado, em relação à hipotese nula. Portanto vamos avaliar:
\[
p = P_{H_0}(X \ge 2).
\]

---
\\
Calculando o valor-p pelo seu valor complementar:
\[
P(X=0) = (0.9)^6 = 0.531441, \qquad 
P(X=1) = \binom{6}{1}(0.1)(0.9)^5 = 0.354294.
\]

Logo, a probabilidade testada é o complemento da soma dessas probabilidades:
\[
valor-p = 1 - [P(X=0) + P(X=1)] = 1 - (0.531441 + 0.354294) = 0.114265.
\]

\[
\boxed{\text{valor-p} = 0.114265}
\]

---

Este resultado \textbf{não é improvável} sob $H_0$ (<0.05).  
Portanto, não há evidência para rejeitar  $H_0$, isto é, não evidências de que $\theta = 0.1$ seja incompatível com os dados.

\[
\boxed{\text{Conclusão: Não há evidências suficientes para rejeitar } H_0 : \theta = 0.1.}
\]
