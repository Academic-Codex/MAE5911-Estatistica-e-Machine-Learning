\paragraph{(a) \(g(\theta)=P_\theta(Z=0)\)}

\[
  g(\theta)=P_\theta(Z=0)=1-\theta.
\]

Pelo teorema da \textbf{invariância do EMV}:
\[
  \widehat g_{MV}=g(\widehat\theta_{MV})=1-\widehat\theta_{MV}.
\]

Já encontramos que \(\widehat\theta_{MV}=\overline Z\), então:
\[
  \boxed{\widehat g_{MV}=1-\overline Z}.
\]



\paragraph{(b) \(g(\theta)=\mathrm{Var}_\theta(Z)\)}

\[\]
Para uma Bernoulli, a variância é dada por:
\[
  \mathrm{Var}(Z)=E(Z^2)-E(Z)^2.
\]

Pela definição de esperança para variáveis discretas,
\[
  E(Z) = \sum_{z \in \{0,1\}} z \, P(Z = z).
\]

Mas $P(Z=1)=\theta$ e $P(Z=0)=1-\theta$, então:
\[
  E(Z)
  = 0 \cdot (1-\theta) + 1 \cdot \theta
  = \theta.
\]

\(E(Z^2)=E(Z)=\theta\) (pois \(Z\in\{0,1\}\)), então:
\[
  \mathrm{Var}_\theta(Z)=\theta-\theta^2=\theta(1-\theta).
\]

Portanto:
\[
  g(\theta)=\mathrm{Var}_\theta(Z)=\theta(1-\theta).
\]
Pela \textbf{invariância do EMV}:
\[
  \widehat g_{MV}=g(\widehat\theta_{MV})
  =\widehat\theta_{MV}(1-\widehat\theta_{MV}).
\]

Para \(\widehat\theta_{MV}=\overline Z\), encontramos:
\[
  \boxed{\widehat g_{MV}=\overline Z(1-\overline Z).}
\]



\paragraph{(c) Sejam os dados observados: \( (0, 0, 1, 0, 0, 1) \)}
\[\]
Para o cálculo da média temos: \( n = 6 \) e \( \sum z_i = 2 \), portanto
\[
  \hat{\theta}_{MV} = \bar{Z} = \frac{2}{6} = \frac{1}{3}.
\]
Assim:
\[
  (a) \quad\hat{g_{MV}}=\widehat{P(Z=0)} = 1 - \hat{\theta}_{MV} = \frac{2}{3},
\]
\[
  (b) \quad\hat{g_{MV}}=\widehat{\mathrm{Var}}(Z) = \hat{\theta}_{MV}(1 - \hat{\theta}_{MV})
  = \frac{1}{3} \cdot \frac{2}{3} = \frac{2}{9}.
\]

---

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
