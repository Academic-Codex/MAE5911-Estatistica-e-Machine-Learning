Podemos calcular os ítens (a) e (b) utilizando a propriedade de invariância do estimador de máxima verossimilhança (EMV).

\textbf{Teorema (Invariância do EMV).}
Seja $\hat\theta_{MV}$ o estimador de máxima verossimilhança de um parâmetro
$\theta \in \Theta$ e seja $g:\Theta \to \mathcal{G}$ uma função.
Então o estimador de máxima verossimilhança de
\[
    \tau = g(\theta)
\]
é dado por
\[
    \hat\tau_{MV} = g(\hat\theta_{MV}).
\]
Isto é, para obter o EMV de qualquer função de $\theta$, basta aplicar essa
função ao EMV de $\theta$.

\medskip

\subsection*{Cálculo do EMV de $\theta$ ( $\hat\theta_{MV}$)}

\textbf{Função de verossimilhança}

Seja $z_1,\dots,z_n$ uma amostra aleatória de $Z \sim \mathrm{Bernoulli}(\theta), \quad \theta \in (0,1)$. Com:
$$
    P_\theta(z_i = 1) = \theta,
    \qquad
    P_\theta(z_i = 0) = 1 - \theta.
$$

A função de probabilidade para Z = $z_i$ é então:
\[
    f(z_i;\theta) = \theta^{z_i}(1-\theta)^{1-z_i}.
\]

Como $z_1,\dots,z_n$ são independentes, a probabilidade conjunta, definida como a função de verossimilhança é o produto das densidades individuais:
\[
    \ell(\theta, z_1,\dots,z_n)
    = \prod_{i=1}^n \theta^{z_i}(1-\theta)^{1-z_i}.
\]

\text{Utilizando a propriedade de produto de exponenciais, temos:}
\[
    \ell(\theta, z_1,\dots,z_n)
    = \theta^{\sum_{i=1}^n z_i}\,(1-\theta)^{\sum_{i=1}^n (1-z_i)}
    = \theta^{\sum_{i=1}^n z_i}\,(1-\theta)^{n-\sum_{i=1}^n z_i}.
\]

Seja
\[
    S = \sum_{i=1}^n z_i,
\]
Podemos escrever:
\[
    \ell(\theta, S) = \theta^{S}(1-\theta)^{n-S}.
\]

\medskip

\textbf{Função Log-verossimilhança}

Podemos simplificar os cálculos trabalhando com o logaritmo desta função, mantendo o estimador de máxima verossimilhança inalterado, uma vez que este trata-se do ponto crítico desta função.
Maximizar $\ell(\theta)$ ou
$\mathcal{L}(\theta) = \log \ell(\theta)$ é equivalente, devido ao fato do logaritmo ser estritamente crescente. Portanto, aplicando o logaritmo, simplificamos para:
\[
    \mathcal{L}(\theta, S)
    = \log \ell(\theta, S)
    = \log\big(\theta^{S}(1-\theta)^{n-S}\big)
    = S\log\theta + (n-S)\log(1-\theta).
\]

\medskip

\textbf{Ponto crítico da log-verossimilhança}

Calculando a derivada de $\mathcal{L}(\theta, S)$ em relação a $\theta$:
\[
    \frac{\partial\mathcal{L}(\theta, S)}{\partial\theta}=
    \frac{\partial}{\partial\theta}\bigl[S\log\theta + (n-S)\log(1-\theta)\bigr] =
    S \cdot \frac{1}{\theta}
    + (n-S)\cdot\left(-\frac{1}{1-\theta}\right)
    = \frac{S}{\theta} - \frac{n-S}{1-\theta}.
\]

Seja a condição de máximo onde está definido $\hat\theta_{MV}$:
\[
    \frac{\partial\mathcal{L}(\theta, S)}{\partial\theta} = 0
    \iff \frac{S}{\hat\theta_{MV}} - \frac{n-S}{1-\hat\theta_{MV}} = 0.
\]

\[
    \frac{S}{\hat\theta_{MV}} = \frac{n-S}{1-\hat\theta_{MV}}.
\]

\[
    S(1-\hat\theta_{MV}) = \hat\theta_{MV}(n-S).
\]

\[
    S - S\hat\theta_{MV} = n\hat\theta_{MV} - S\hat\theta_{MV}.
\]

Os termos $-S\hat\theta_{MV}$ cancelam em ambos os lados, restando:
\[
    S = n\hat\theta_{MV}.
\]

Isolando $\hat\theta_{MV}$:
\[
    \boxed{
        \hat\hat\theta_{MV} = \frac{S}{n}.
    }
\]

\textbf{Estimador de máxima verossimilhança}

Substituindo de volta em funcão da variável aleatória $z_i$, obtemos:
\[
    \hat\theta_{MV}
    = \frac{1}{n}\sum_{i=1}^n z_i
    = \bar Z.
\]

\subsubsection*{Teste de hipótese}

O teste de hipótese é fomulado como um framework de decisão. No processo de decisão existem dois possíveis cenários de enganos,
sendo que ambos não podem ser reduzidos simultaneamente, a menos do aumento da amostra, e se um cenário de engano diminui o seu complementar aumenta.
Escolhe-se por arbitrariedade priorizar a mitigação do erro \textbf{falso positivo}, em detrimento do erro \textbf{falso negativo}.
Desta forma a hipótese nula é definida como a hipótese que se deseja refutar. Entretanto, o teste é construído para que
haja apenas uma baixa probabilidade, comumente $5\%$, de que H0 seja refutada, ou seja, a sua rejeição é definida como um evento raro.
Consequentemente, quando ela é rejeitada, considera-se que o processo de decisão está com uma margem de erro suficientemente reduzida, de acordo com o
nível de significância escolhido, que reflete a magnitude do erro tolerado.

Deste framework, o valor-p é a métrica que caracteriza a amostra observada no cenário em que a hipótese nula é verdadeira. O valor-p então calculado é
comparado com o nível de significância escolhido para que a decisão de rejeitar ou não a hipótese nula seja tomada.
