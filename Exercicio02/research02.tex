Podemos calcular os ítens (a), (b) e (c) utilizando a propriedade de invariância do estimador de máxima verossimilhança (EMV), calculando uma única vez $\hat\theta_{MV}$.

\subsection*{Cálculo do EMV de $\theta$ ( $\hat\theta_{MV}$) para a distribuição Exponencial}

\textbf{Função de verossimilhança}

Seja $(z_1,\dots,z_n)$ uma amostra aleatória de $Z \sim \text{Exp}(\theta)$, com $ \theta \in (0,\infty)$, a função densidade de probabilidade para $z_i$ é então:
\[
      f(z_i;\theta) = \theta e^{-\theta z_i}, \qquad z_i>0.
\]

Como $z_1,\dots,z_n$ são independentes, a probabilidade conjunta, definida como a função de verossimilhança é o produto das densidades individuais:
\[
      \ell(\theta;z_1,\dots,z_n)
      = \prod_{i=1}^n f(z_i\mid \theta)
      = \prod_{i=1}^n \theta e^{-\theta z_i} \mathbf 1_{\{z_i>0\}}.
\]

O termo indicador $\prod_{i=1}^n \mathbf 1_{\{z_i>0\}}$ não depende de $\theta$, logo
não influencia a maximização e pode ser ignorado. Assim,
\[
      \ell(\theta;z_1,\dots,z_n)
      = \prod_{i=1}^n \theta e^{-\theta z_i}.
\]

Aplicando a propriedade distributiva do produto e de produto de exponenciais, obtemos:
\[
      \ell(\theta;z_1,\dots,z_n)
      = \biggl(\prod_{i=1}^n \theta\biggr)
      \biggl(\prod_{i=1}^n e^{-\theta z_i}\biggr)
      = \theta^n \exp\!\left(-\theta\sum_{i=1}^n z_i\right).
\]

Seja
\[
      S = \sum_{i=1}^n z_i,
\]
Podemos escrever:
\[
      \ell(\theta,S) = \theta^n \exp(-\theta S).
\]

\textbf{Função log-verossimilhança}

Para simplificar os cálculos, trabalhamos com a função logaritmo da verossimilhança $\mathcal{L}(\theta, S)$:
\[
      \mathcal{L}(\theta, S) = \log \ell(\theta,S)
      = \log(\theta^n) + \log\!\left(\exp(-\theta S)\right).
\]

Usando as propriedades $\log(a^b)=b\log a$ e $\log(e^x)=x$, obtemos
\[
      \mathcal{L}(\theta, S) = n\log\theta - \theta S.
\]

\textbf{Ponto crítico da log-verossimilhança}

Calculando a derivada de $\mathcal{L}(\theta, S)$ em relação a $\theta$:
\[
      \frac{\partial\mathcal{L}(\theta, S)}{\partial\theta}
      = \frac{\partial}{\partial\theta}\bigl[n\log\theta - \theta S\bigr]
      = n\cdot\frac{1}{\theta} - S\cdot 1
      = \frac{n}{\theta} - S.
\]

Seja a condição de máximo onde está definido $\hat\theta_{MV}$:
\[
      \frac{\partial\mathcal{L}(\theta, S)}{\partial\theta} = 0
      \iff
      \frac{n}{\hat\theta_{MV}} - S = 0
      \iff
      \frac{n}{\hat\theta_{MV}} = S.
\]

Isolando $\hat\theta_{MV}$:

\[
      \boxed{
            \hat\theta_{MV}
            = \frac{n}{S},
      }
\]

\textbf{Estimador de máxima verossimilhança}

Substituindo de volta em funcão da variável aleatória $z_i$, obtemos:
\[
      \hat\theta_{MV}
      = \frac{n}{\sum_{i=1}^n z_i}
      = \frac{1}{\bar Z},
\]


\subsection*{Intervalo de confiança}

Conhecendo a \textbf{distribuição de probabilidade de} $\hat\theta$ é possível construir um intervalo $$\hat\theta_1 \leq \theta \leq \hat\theta_2$$ que contém $\theta$.
Esta técnica diferencia-se da estimação "por ponto", onde se calcula um único valor para o parâmetro populacional. No caso do intervalo de confiança busca-se um
seguimento, ou intervalo $\hat\theta_1:\hat\theta_2$ que contém o parâmetro desconhecido (FONSECA, 2008, p. 186).


% \paragraph{Composição da distribuição Exponencial contínua acumulada.}
% \vspace{1em}
% Separando a distribuição exponencial em função de distribuição acumulada até a observação de interesse e
% o restante da distribuição acumulada denominada a cauda da distribuição, temos:
% \\[1em]
% Expressão para densidade total: \[f(z_i\mid\theta)=\theta e^{-\theta z_i}\mathbf 1_{\{z_i\ge0\}}.\] \\
% Função de distribuição acumulada: \[F(z)=P_\theta(Z\le z)=\int_0^z \theta e^{-\theta t}\,dt
%       =\big[-e^{-\theta t}\big]_0^z=1-e^{-\theta z}.\] \\
% Cauda: \[P_\theta(Z>z)=1-F(z)=e^{-\theta z}.\]