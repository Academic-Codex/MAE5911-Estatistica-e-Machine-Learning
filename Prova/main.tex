\documentclass[a4paper]{article}
\usepackage{student}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[version=4]{mhchem}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, decorations.pathreplacing}
\usepackage{enumitem}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{float}
\usepackage[portuguese]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[numbers,sort&compress]{natbib} % ou [authoryear]
\usepackage[alf]{abntex2cite} % citação ABNT autor-data
\usepackage{listings}
\usepackage{xcolor}
\usepackage{url}
\lstset{
  basicstyle=\ttfamily\small,
  commentstyle=\color{gray}\itshape,
  keywordstyle=\color{blue},
  stringstyle=\color{orange},
  frame=single,
  backgroundcolor=\color{gray!5},
  breaklines=true,
  captionpos=b
}
% --- Suporte a UTF-8 ---
\usepackage{lmodern}           % fonte moderna compatível com T1

% --- Pacotes para exibir código ---


% --- Define o idioma R com palavras-chave e cores ---
\lstdefinelanguage{R}{
  keywords={function, if, else, for, in, while, repeat, return, library, require, next, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={TRUE, FALSE, NULL, NA, Inf, NaN},
  ndkeywordstyle=\color{magenta}\bfseries,
  comment=[l]{\#},
  commentstyle=\color{gray}\ttfamily,
  stringstyle=\color{orange}\ttfamily,
  morestring=[b]",
  morestring=[b]',
  sensitive=true
}

% --- Mapeamento para UTF-8 (acentos, ç, etc.) ---
\lstset{
  literate=
    {á}{{\'a}}1 {ã}{{\~a}}1 {â}{{\^a}}1 {à}{{\`a}}1
    {é}{{\'e}}1 {ê}{{\^e}}1
    {í}{{\'i}}1
    {ó}{{\'o}}1 {õ}{{\~o}}1 {ô}{{\^o}}1
    {ú}{{\'u}}1 {ü}{{\"u}}1
    {ç}{{\c{c}}}1
    {Á}{{\'A}}1 {Ã}{{\~A}}1 {Â}{{\^A}}1
    {É}{{\'E}}1 {Ê}{{\^E}}1
    {Í}{{\'I}}1
    {Ó}{{\'O}}1 {Õ}{{\~O}}1 {Ô}{{\^O}}1
    {Ú}{{\'U}}1 {Ü}{{\"U}}1
    {Ç}{{\c{C}}}1,
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{gray!5},
  frame=single,
  breaklines=true,
  captionpos=b,
  columns=flexible,
  showstringspaces=false,
  keepspaces=true,
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=6pt
}
\pagestyle{plain}

\tikzstyle{arrow} = [thick,->,>=stealth]

% Definindo o estilo de destaque com linhas pontilhadas
\tikzstyle{highlight} = [draw, dashed, thick, rectangle, rounded corners, inner sep=0.2cm, orange]


\tikzstyle{startstop} = [
    rectangle, rounded corners, minimum width=0.5cm,
    text centered, draw=black, fill=blue!10, font=\small
]
\tikzstyle{startstop_S} = [
    rectangle, rounded corners, minimum width=0.5cm, minimum height=0.8cm,
    text centered, draw=black, fill=green!30, font=\small
]
\tikzstyle{decision} = [
    diamond, aspect=2, draw=black, fill=orange!15, align=center,
    text centered, inner sep=0pt, font=\small
]
\tikzstyle{decision_S} = [
    diamond, aspect=2, draw=black, fill=orange!30, align=center,
    text centered, inner sep=0pt, font=\small
]
\tikzstyle{arrow} = [thick,->,>=stealth]



% Metadata
\date{\today}
\setmodule{MAE5911/IME: Fundamentos de Estatística e Machine Learning. \\ Prof.: Alexandre Galvão Patriota} 
\setterm{2o. semestre, 2025}

%-------------------------------%
% Other details
% TODO: Fill these
%-------------------------------%
\title{Prova - 04/11}
\setmembername{Nara Avila Moraes}  % Fill group member names
\setmemberuid{5716734}  % Fill group member uids (same order)

%-------------------------------%
% Add / Delete commands and packages
% TODO: Add / Delete here as you need
%-------------------------------%
\usepackage{amsmath,amssymb,bm}

\newcommand{\KL}{\mathrm{KL}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\T}{\top}

\newcommand{\expdist}[2]{%
        \normalfont{\textsc{Exp}}(#1, #2)%
    }
\newcommand{\expparam}{\bm \lambda}
\newcommand{\Expparam}{\bm \Lambda}
\newcommand{\natparam}{\bm \eta}
\newcommand{\Natparam}{\bm H}
\newcommand{\sufstat}{\bm u}

% Main document
\begin{document}
    % Add header
    \header{}

\textbf{Questão 01:} Defina formalmente o valor-p (\textbf{aproximado}) para testar uma hipótese geral e discuta os problemas de interpretação usuais ao utilizar a sua versão condicional à hipótese nula. Apresente um exemplo numérico e simulações de Monte Carlo, usando um modelo de regressão Poisson, para ilustrar a sua aplicação. \\[0.5cm]
\textbf{Questão 02:} Apresente um Teorema da Aproximação Universal que generalize o Teorema de Funahashi, discuta as diferenças entre os resultados por meio de exemplos de redes neurais. \\[0.5cm]
\textbf{Questão 03:} Proponha uma função de estimação robusta para estimar os parâmetros de uma regressão Binomial, $Y|X=x \sim \mathrm{Bin}(m,\mu_\theta(x))$, em que $\mu_\theta(\cdot)$ é uma função com imagem em $[0,1]$ e $\theta$ é o vetor de parâmetros. Apresente um exemplo numérico e uma simulação de Monte Carlo, como feito em sala, para ilustrar os resultados. Perturbe a distribuição dos dados e mostre que a sua proposta é de fato robusta contra essa perturbação. \\[0.5cm]
\begin{answer}[Questão 01]
O conceito do p-valor, tal como proposto originalmente por \textit{Fisher} (1925), é uma medida \textbf{condicional sob} $H_0$, definida por
\[
\text{valor-p}(H_0, z_n) = \sup_{\theta \in \Theta_0} P_\theta^{(n)}\big(T_{H_0}(Z_n) \ge T_{H_0}(z_n)\big),
\]
isto é, a probabilidade de se observar uma estatística tão extrema quanto a obtida, assumindo $H_0$ verdadeira.
O valor-p foi concebido por Fisher como um \textit{instrumento de contraste} entre o dado e hipótese, mas não como uma medida de verdade.
Seu objetivo era expressar o grau de incompatibilidade empírica entre o fenômeno observado e as consequências lógicas de $H_0$.

Posteriormente, a escola \textit{Neyman--Pearson} reinterpretou esse conceito dentro de uma estrutura de decisão.
Nessa transição, o valor-p perdeu seu caráter exploratório e passou a ser tratado como um critério binário, externo e supostamente não condicionado a $H_0$, capaz de expressar a decisão: ``rejeita'' ou ``não rejeita'' $H_0$.
Esta leitura gerou um equívoco lógico: o valor-p, que é definido dentro do universo em que $H_0$ é verdadeira,
passou a ser interpretado como se pudesse mensurar a probabilidade de $H_0$ ser verdadeira.

O \textbf{valor-p assintótico}, que é o valor usualmente utilizado, na ausência da distribuição exata de $T_{H_0}$, é definido por:
\[
p^{(a)}(H_0, z_n) = \sup_{\theta \in \Theta_0} P_\theta(W_\theta \ge T_{H_0}(z_n)),
\]
em que $W_\theta$ representa a distribuição-limite de $T_{H_0}$ quando $n \to \infty$.

Confirmando essa natureza epistêmica, o valor-p assintótico nem sempre converge para o valor-p exato, isto porque, estando definido condicionalmente a $H_0$, pode não ser sensível a falhas estruturais do modelo, 
como a ausência de independência entre as observações, a presença de hipóteses condicionais aninhadas, ou a violação das condições de regularidade que garantem a validade assintótica — 
como homocedasticidade. 

Por isso, o valor-p deve ser entendido apenas como originalmente proposto — 
uma \textbf{medida de discrepância entre o real e o teórico} — 
que opera em um único sentido: como evidência contra a hipótese nula, mas nunca para confirmá-la.

Em termos das $\sigma$-álgebras envolvidas, a construção inferencial pode ser representada como uma sequência de aplicações mensuráveis, onde cada espaço de probabilidade possui a sua própria $\sigma$-álgebra, refletindo níveis distintos de abstração:
\[
(\Omega_n, \mathcal{F}_n, \mathbb{P}_n)
\;\xrightarrow{Z_n}\;
(\mathcal{Z}_n, \mathcal{B}_{Z_n}, \mathbb{P}_{Z_n})
\;\xrightarrow{T}\;
(\mathcal{T}_n, \mathcal{B}_{T_n}, \mathbb{P}_{T_n}).
\]

\begin{itemize}
    \item $\mathcal{F}_n$ — descreve o universo empírico de incertezas, isto é, os eventos do mundo observável;
    \item $\mathcal{B}_{Z_n}$ — corresponde ao espaço amostral modelado, onde as variáveis aleatórias $Z_n$ são definidas sob $\mathbb{P}_{Z_n}$;
    \item $\mathcal{B}_{T_n}$ — é a $\sigma$-álgebra induzida pela estatística $T$, onde vivem as distribuições teóricas dos testes e, em particular, o valor-p.
\end{itemize}

O valor-p pertence ao universo lógico em que a hipótese nula $H_0$ é assumida como verdadeira.
Ele não pertence à $\sigma$-álgebra empírica $\mathcal{F}_n$, e portanto não pode ser interpretado
como uma probabilidade sobre o mundo real ou sobre a veracidade de $H_0$.
Tratá-lo dessa forma constitui um erro de violação da $\sigma$-álgebra — 
um deslize epistemológico em que se tenta extrair informação empírica de uma construção em sua definição epistêmica condicional e autoreferente.

\subsection*{Implementações}

O exemplo numérico apresentado na Listing~\ref{lst:poisson-numerico} tem o objetivo de ilustrar o comportamento do valor-$p$ sob diferentes hipóteses nulas, mantendo fixos os dados observados. 
O experimento baseia-se em um modelo de regressão de Poisson definido por
\[
Y_i \sim \text{Poisson}(\lambda_i), \quad \text{com} \quad \log(\lambda_i) = \theta_0 + \theta x_i,
\]
onde $\theta_0 = 1$ e o valor verdadeiro do parâmetro é $\theta = 0{,}20$. 
Uma única amostra de tamanho $n = 200$ foi gerada segundo esse modelo, representando o conjunto de dados ``observados'' em um mundo empírico fixo.

A partir dessa amostra, foram testadas três hipóteses nulas distintas sobre o mesmo conjunto de dados:
\[
H_{0}^{(A)} : \theta = 0{,}20, \qquad
H_{0}^{(B)} : \theta = 0{,}10, \qquad
H_{0}^{(C)} : \theta = 0{,}60.
\]
Cada hipótese foi avaliada por meio da estatística de Wald,
\[
Z = \frac{\hat{\theta} - \theta_{H_0}}{\operatorname{se}(\hat{\theta})},
\]
e o valor-$p$ correspondente foi calculado de forma:
\[
p = P(Z \ge z_{\text{obs}}),
\]

Os resultados obtidos encontram-se na Tabela~\ref{tab:resultado_simulacao}. 
Observa-se que, quando a hipótese nula coincide com o valor real do parâmetro ($\theta$), o valor-$p$ é elevado e a hipótese não é rejeitada. 
À medida que o valor hipotético se afasta de $\theta$, o valor-$p$ decresce rapidamente, levando à rejeição de $H_0$ nos casos de maior discrepância ($H_{0}^{(C)}$). 
Essa simulação evidencia o papel do valor-$p$ como medida de compatibilidade entre modelo e dado: ele quantifica o grau de discrepância entre a hipótese estatística e a estrutura empírica observada.

\begin{table}[H]
\centering
\caption{Resultados do cálculo do valor-$p$ para diferentes hipóteses nulas sob o modelo de regressão de Poisson.}
\label{tab:resultado_simulacao}
\begin{tabular}{lccccc}
\toprule
\textbf{Cenário} & \textbf{Hipótese nula} & \textbf{Valor-$p$} & \textbf{Decisão} & \textbf{$\hat{\theta}$} & \textbf{$\theta$} \\
\midrule
Cenário A ($H_{0}^{(A)}$ exato) & $\theta_{H_0} = 0{,}20$ & 0{,}212614 & Não rejeita $H_0$ & 0{,}254359 & 0{,}2 \\
Cenário B ($H_{0}^{(B)}$ com pequeno desvio) & $\theta_{H_0} = 0{,}10$ & 0{,}011779 & Rejeita $H_0$ & 0{,}254359 & 0{,}2 \\
Cenário C ($H_{0}^{(C)}$ com grande desvio) & $\theta_{H_0} = 0{,}60$ & 1{,}000000 & Não rejeita $H_0$ & 0{,}254359 & 0{,}2 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Simulação de Monte Carlo (regressão de Poisson).}
Fixamos um desenho \(x_i \sim \text{Unif}(0,2)\) e geramos, em cada replicação,
um conjunto de dados \(Y_i \sim \text{Poisson}(\lambda_i)\) com
\(\log \lambda_i = \beta_0 + \theta x_i\), onde \(\beta_0 = 1\) e \(\theta = 0{,}20\).
Em cada amostra, ajustamos um GLM de Poisson e testamos, com o \emph{mesmo} conjunto de dados,
três hipóteses nulas sobre o coeficiente de \(x\): \(H0_A:\theta = 0{,}20\),
\(H0_B:\theta = 0{,}10\) e \(H0_C:\theta = 0{,}60\).
O valor-$p$ utilizado é o assintótico (Wald) \emph{unicaudal à direita},
\(p = \Pr(Z \ge z_{\text{obs}})\), com
\(Z = (\hat\theta - \theta_{H_0})/\mathrm{se}(\hat\theta)\).
A partir de \(M\) replicações, reportamos (para cada cenário) a proporção de rejeições
(\emph{erro tipo~I} quando \(H0_A\) é verdadeiro, \emph{potência} quando \(H0_B\) e \(H0_C\) são falsos),
bem como estatísticas resumidas da distribuição dos valores-$p$ e a média de \(\hat\theta\).

Quando \(H0_A\) coincide com o parâmetro verdadeiro, a proporção de rejeição aproxima-se de \(\alpha\),
e os valores-$p$ apresentam distribuição aproximadamente uniforme (com pequenas distorções finitas).
Para \(H0_B\) (desvio pequeno), a potência cresce moderadamente; para \(H0_C\) (desvio grande),
a potência aproxima-se de 1 e os valores-$p$ concentram-se próximos de 0.
Esses resultados ilustram o papel do valor-$p$ como medida de \emph{compatibilidade}
entre hipótese e dado: quanto maior a discrepância \(\theta_{H_0}-\theta\) na direção do teste,
menor tende a ser o valor-$p$ e maior a taxa de rejeição.
\end{answer}


Nas simulações de Monte Carlo realizadas sob $H_0$, os p-valores mostraram-se aproximadamente uniformes, 
reproduzindo o comportamento esperado quando as condições assintóticas são satisfeitas. 
No entanto, ao introduzir pequenas violações, como superdispersão ou dependência entre observações, 
a distribuição dos p-valores tornou-se assimetricamente inclinada, evidenciando a sua sensibilidade à estrutura do modelo. \\[2em]
Esse resultado empírico confirma que a discrepância entre o valor-p exato e o assintótico não é meramente numérica, 
mas reflete o descompasso lógico entre o universo ideal de $H_0$ e o comportamento real dos dados. 

\begin{lstlisting}[language=R, caption={Exemplo numérico - Regressão Poisson}, label={lst:poisson-numerico}]
# ====================================================================
# Regressão Poisson
# ====================================================================

set.seed(123)

# Parâmetros
n = 200
beta0 = 1.0
beta1_real = 0.20   # efeito verdadeiro fixo
alpha = 0.05

# Covariável e única amostra gerada do mundo real
x = runif(n, 0, 2)
lambda = exp(beta0 + beta1_real * x)
y = rpois(n, lambda)

# Ajuste único nos mesmos dados
modelo = glm(y ~ x, family = poisson)

# ---------------------------------------------------------------
# Função: testa H0: beta1 = b0 (teste de Wald)
# ---------------------------------------------------------------
testa_glm_1amostra = function(mod, b0) {
  b1_hat = coef(mod)[2]
  se_b1  = sqrt(vcov(mod)[2, 2])
  Z = (b1_hat - b0) / se_b1
  p_valor = 2 * (1 - pnorm(abs(Z)))   # bicaudal
  decisao = ifelse(p_valor < alpha, "Rejeita H0", "Não rejeita H0")
  data.frame(
    hipotese_nula = paste0("H0: beta1 = ", format(b0, nsmall = 2)),
    valor_p = p_valor,
    decisao = decisao,
    beta1_estimado = b1_hat,
    beta1_real = beta1_real
  )
}

# Hipóteses a testar sobre o mesmo conjunto (exato, pouco e muito desvio)
B0s = c(0.20, 0.10, 0.60)

resA = testa_glm_1amostra(modelo, B0s[1])  # exato 
resB = testa_glm_1amostra(modelo, B0s[2])  # pouco desvio
resC = testa_glm_1amostra(modelo, B0s[3])  # desvio forte

resumo_glm = rbind(
  "Cenário A (H0 exato)"              = resA,
  "Cenário B (H0 com pouco desvio)"   = resB,
  "Cenário C (H0 com muito desvio)"   = resC
)

# Saída formatada (sem <dbl>)
noquote(resumo_glm)
\end{lstlisting}



    \begin{answer}[Questão 02]
    \end{answer}

    \begin{answer}[Questão 03]
    \end{answer}

     \begin{minipage}[c]{0.84\textwidth}
        \hspace{2em}%
        Os códigos desde estudo estão disponibilizados em \url{http://academic-codex.github.io/MAE5911-Estatistica-e-Machine-Learning}.
      \end{minipage}
      \hfill
      \begin{minipage}[c]{0.13\textwidth}
    \centering
        \includegraphics[width=0.7\linewidth]{figuras/qrcode.png}
      \end{minipage}
\end{document}