print("Olá mundo!")
2+2
2 -> b
0:100
2 -> b
c <- d <- e <- 3
x <- c(1, 2, 5, 9)
x
0:10
10:0
seq(10)  # Crescente de 1 a 10
seq(30, 0, by = -3)  # Decrescendo de 3 em 3
(y <- c(5, 1, 0, 10))
x + y
z <- x + y
x * 2
j <- x * 2
2^6
log(100)
log10(100)
rm(list = ls())
cat("\014")
(numero_1 <- 15)
typeof(numero_1)
(numero_2 <- 1.5)
typeof(numero_2)
(uma_letra <- "c")
typeof(uma_letra)
(texto <- "uma mensagem de texto")
typeof(texto)
(boleano <- TRUE)
typeof(boleano)
(vetor_1 <- c(1, 2, 3, 4, 5))
is.vector(vetor_1)
(vetor_2 <- c("a", "b", "c"))
is.vector(vetor_2)
vetor_3 <- c(TRUE, TRUE, FALSE, FALSE, TRUE)
vetor_3
is.vector(vetor_3)
source("Config.R")
setwd("/Users/chanahyo/Repository/Academic-Codex/MAE5911-Estatistica-e-Machine-Learning/Exercício03/code_02")
source("Config.R")
library(torch)
source("Data.R")
source("Model.R")   # aqui já estão HeteroNormalNet, QuantileNormalNet, etc.
source("Train.R")
# ------------------------------------------------------------------
# escolhe o nível de quantil (pego do Config, mas pode ser fixo)
q_level <- config$q  # por ex., 0.75
# cria o modelo de quantil + variância heteroscedástica
model <- QuantileNormalNet(
input_dim    = 1,
hidden_q     = 10,
hidden_sigma = 10
)
# treina
res <- treinar_normal_quantil(
model      = model,
q_level    = q_level,
epochs     = 10000,
lr         = 2e-3
)
