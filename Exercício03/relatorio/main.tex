\documentclass[a4paper]{article}
\usepackage{student}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[version=4]{mhchem}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, decorations.pathreplacing}
\usepackage{enumitem}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{float}
\usepackage[portuguese]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[numbers,sort&compress]{natbib} % ou [authoryear]
\usepackage[alf]{abntex2cite} % citação ABNT autor-data
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage{tikz}
\usetikzlibrary{positioning,shapes.geometric,arrows.meta,calc}
% --- TikZ básico ---
\usepackage{tikz}

% --- Bibliotecas necessárias ---
\usetikzlibrary{positioning}   % para node distance, below=..., right=...
\usetikzlibrary{shapes.geometric} % caixas arredondadas, shapes
\usetikzlibrary{arrows.meta}   % setas melhores
\usetikzlibrary{calc}          % coordenadas TikZ avançadas (útil p/ labels)

% --- Tabela bonita (para top/mid/bottom rule) ---
\usepackage{booktabs}

% --- Para usar [H] ---
\usepackage{float}

% --- Fonte menor no caption e figure ---
\usepackage{caption}
\tcbuselibrary{breakable}
\pagestyle{plain}

\tikzstyle{arrow} = [thick,->,>=stealth]

% Definindo o estilo de destaque com linhas pontilhadas
\tikzstyle{highlight} = [draw, dashed, thick, rectangle, rounded corners, inner sep=0.2cm, orange]


\tikzstyle{startstop} = [
    rectangle, rounded corners, minimum width=0.5cm,
    text centered, draw=black, fill=blue!10, font=\small
]
\tikzstyle{startstop_S} = [
    rectangle, rounded corners, minimum width=0.5cm, minimum height=0.8cm,
    text centered, draw=black, fill=green!30, font=\small
]
\tikzstyle{decision} = [
    diamond, aspect=2, draw=black, fill=orange!15, align=center,
    text centered, inner sep=0pt, font=\small
]
\tikzstyle{decision_S} = [
    diamond, aspect=2, draw=black, fill=orange!30, align=center,
    text centered, inner sep=0pt, font=\small
]
\tikzstyle{arrow} = [thick,->,>=stealth]



% Metadata
\date{\today}
\setmodule{MAE5911/IME: Fundamentos de Estatística e Machine Learning. \\ Prof.: Alexandre Galvão Patriota} 
\setterm{2o. semestre, 2025}

%-------------------------------%
% Other details
% TODO: Fill these
%-------------------------------%
\title{Lista 03 - 21/11}
\setmembername{Nara Avila Moraes}  % Fill group member names
\setmemberuid{5716734}  % Fill group member uids (same order)

%-------------------------------%
% Add / Delete commands and packages
% TODO: Add / Delete here as you need
%-------------------------------%
\usepackage{amsmath,amssymb,bm}

\newcommand{\KL}{\mathrm{KL}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\T}{\top}

\newcommand{\expdist}[2]{%
        \normalfont{\textsc{Exp}}(#1, #2)%
    }
\newcommand{\expparam}{\bm \lambda}
\newcommand{\Expparam}{\bm \Lambda}
\newcommand{\natparam}{\bm \eta}
\newcommand{\Natparam}{\bm H}
\newcommand{\sufstat}{\bm u}

% Main document
\begin{document}
% Add header
\header{}



\textbf{Questão 01:}
Considere uma amostra aleatória $(Y_1,X_1),\ldots,(Y_n,X_n)$ de $(Y,X)$ tal que a distribuição condicional
$Y \mid X = x \sim \mathcal{N}\big(\mu_{\theta}(x),\,\sigma^{2}_{\theta}(x)\big),$
e suponha que a distribuição de $X$ não contém informação sobre os parâmetros.


\begin{enumerate}[leftmargin=2.5cm, itemindent=0pt, label=\textbf{Ítem 1.\arabic*}]
    \item[\textbf{Ítem 1.1}] Apresente uma \textbf{rede neural} que modele o \textbf{quantil de ordem $75\%$} (terceiro quartil) da distribuição condicional $Y \mid X = x$.  O código deve ser generalizável para qualquer quantil.

    \item[\textbf{Ítem 1.2}] Mostre a aplicação do método nos seguintes dados simulados em \textsf{R}:
          \noindent
          \begin{tcolorbox}[
                  width=\linewidth,
                  colback=white,
                  colframe=black,
                  boxrule=0.2pt,   % <<< mais fino (padrão é 0.5pt)
                  left=0mm
              ]

              \[
                  \text{set.seed}(32)
              \]

              \[
                  n = 1000
              \]

              \[
                  x = \operatorname{sort}(\operatorname{runif}(n,-4,4))
              \]

              \[
                  y = \frac{3}{3 + 2|x|^{3}} + e^{-x^{2}} + \cos(x)\sin(x) + 0.3\,\varepsilon,
                  \qquad \varepsilon \sim \mathcal{N}(0,1)
              \]

          \end{tcolorbox}


\end{enumerate}
\noindent
Sugestão: reescreva a esperança e variância condicionais em termos do quantil
e construa a função de verossimilhança apropriada.

\begin{answer}[Ítem 1.1]
    \subsubsection*{Encontrando a função de verossimilhança em termos do quantil condicional}

    Seja
    \begin{equation}
        Y \mid X = x \sim \mathcal{N}\big(\mu(x), \sigma^2(x)\big).
    \end{equation}

    Para um nível de quantil $q \in (0,1)$, definimos o quantil condicional
    $Q_q(x)$ de $Y \mid X=x$ como o valor $t$ que satisfaz
    \begin{equation}
        \mathbb{P}\!\big( Y \le t \,\big|\, X = x \big) = q.
    \end{equation}

    No caso da Normal, o quantil condicional pode ser escrito em termos da média
    e do desvio-padrão:
    \begin{equation}
        Q_q(x) = \mu(x) + \sigma(x)\, z_q,
    \end{equation}
    em que $z_q = \Phi^{-1}(q)$ é o quantil de ordem $q$ da Normal padrão
    $\mathcal{N}(0,1)$ e $\Phi$ denota a sua função de distribuição acumulada.

    Podemos, então, reparametrizar o modelo em função de $Q_q(x)$, escrevendo
    \begin{equation}
        \mu(x) = Q_q(x) - \sigma(x)\,z_q.
    \end{equation}

    \subsection{Verossimilhança em termos do quantil}

    A densidade de $Y \mid X=x$ é
    \begin{equation}
        f(y \mid x) =
        \frac{1}{\sqrt{2\pi}\,\sigma(x)}
        \exp\!\left\{
        -\frac{\big(y-\mu(x)\big)^2}{2\sigma^2(x)}
        \right\}.
    \end{equation}

    Substituindo $\mu(x) = Q_q(x) - \sigma(x)z_q$, obtemos
    \begin{equation}
        f(y \mid x) =
        \frac{1}{\sqrt{2\pi}\,\sigma(x)}
        \exp\!\left\{
        -\frac{\big(y - Q_q(x) + \sigma(x) z_q\big)^2}
        {2\sigma^2(x)}
        \right\}.
    \end{equation}

    A log-verossimilhança para uma observação $(x_i,y_i)$, desprezando constantes
    que não dependem de $Q_q$, é dada por
    \begin{equation}
        \ell_i\big(Q_q,\sigma\big)
        = - \log \sigma(x_i)
        - \frac{\big(y_i - Q_q(x_i) + \sigma(x_i) z_q\big)^2}
        {2\sigma^2(x_i)}.
    \end{equation}

    O correspondente negativo da log-verossimilhança (função de perda) é
    \begin{equation}
        \mathcal{L}_{\text{NLL}}
        = \sum_{i=1}^n
        \left[
            \log \sigma(x_i)
            +
            \frac{\big(y_i - Q_q(x_i) + \sigma(x_i) z_q\big)^2}
            {2\sigma^2(x_i)}
            \right].
    \end{equation}


    \subsection*{Descrição do experimento e configuração do modelo}
    \subsubsection*{Hiperparâmetros do modelo}
    \subsubsection*{Arquitetura}

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[
                x=1.8cm, y=1.2cm,
                >=Stealth,
                neuron/.style={circle,draw,minimum size=6mm},
                unicorn/.style={diamond, draw, fill=purple!10,
                        minimum width=18mm, minimum height=10mm},
                actblock/.style={rectangle,draw,rounded corners,
                        minimum width=9mm,minimum height=5mm},
                every node/.style={font=\footnotesize}
            ]

            % ======== INPUT NODE ========
            \node[neuron,label=left:{$x$}] (x) at (0,-1) {};

            % =====================================================
            % ===============  REDE DO QUANTIL  ===================
            % =====================================================

            % 10 neurônios ocultos (posicionados de y=3.5 até ~0.35)
            \foreach \i in {1,...,10}{
                    \node[neuron] (qh\i) at (2,{3.5 - 0.35*(\i-1)}) {};
                }

            % bloco GELU (representa ativação da camada oculta inteira)
            \node[actblock] (geluq) at (3,1.75) {GELU};

            % saída q(x)
            \node[neuron,fill=blue!15,label={[yshift=6pt]right:{$q(x)$}}] (qout) at (3.9,1.75) {};

            % input -> hidden (quantil)  [Linear(1,10): 10 pesos]
            \foreach \i in {1,...,10}{
                    \draw[->] (x) -- (qh\i);
                }

            % hidden -> GELU (quantil)
            \foreach \i in {1,...,10}{
                    \draw[->] (qh\i) -- (geluq.west);
                }

            % GELU -> saída (quantil) [Linear(10,1): 10 pesos]
            \draw[->] (geluq.east) -- (qout.west);

            % labels de parâmetros no ramo do quantil
            % \node at (1.1,3.9) {\scriptsize Linear $(1,10)$: $10$ pesos + $10$ vieses};

            \node[align=center] at (2,4.1) {%
                \scriptsize Linear $(1,10)$:\\
                $10$ pesos + $10$ vieses
            };
            % \node at (3.7,3.0) {\scriptsize Linear $(10,1)$: $10$ pesos + $1$ viés};
            \node[align=center] at (3.8,2.4) {%
                \scriptsize Linear $(10,1)$:\\
                $10$ pesos + $1$ viés
            };

            % label da rede do quantil
            \node at (3,4.7) {\textbf{Rede do Quantil } $Q_\tau(x)$};


            % =====================================================
            % ===============  REDE DA VARIÂNCIA  =================
            % =====================================================

            % 10 neurônios ocultos (y=-1.2 até ~-4.55)
            \foreach \i in {1,...,10}{
                    \node[neuron] (sh\i) at (2,{-1.2 - 0.35*(\i-1)}) {};
                }

            % bloco GELU da variância
            \node[actblock] (gelus) at (3.3,-3.0) {GELU};

            % saída sigma_raw(x)
            \node[neuron,fill=green!15,label=right:{$\sigma_{\mathrm{raw}}(x)$}]
            (sraw) at (3.9,-3.0) {};

            % input -> hidden (variância) [Linear(1,10)]
            \foreach \i in {1,...,10}{
                    \draw[->] (x) -- (sh\i);
                }

            % hidden -> GELU (variância)
            \foreach \i in {1,...,10}{
                    \draw[->] (sh\i) -- (gelus.west);
                }

            % GELU -> saída (variância) [Linear(10,1)]
            \draw[->] (gelus.east) -- (sraw.west);

            % labels de parâmetros no ramo da variância
            % \node at (1.4,-0.1) {\scriptsize Linear $(1,10)$: $10$ pesos + $10$ vieses};
            % \node at (3.9,-1.2) {\scriptsize Linear $(10,1)$: $10$ pesos + $1$ viés};

            \node[align=center] at (2,-0.6) {%
                \scriptsize Linear $(10,1)$:\\
                $10$ pesos + $1$ viés
            };

            \node[align=center] at (3.9,-2.3) {%
                \scriptsize Linear $(10,1)$:\\
                $10$ pesos + $1$ viés
            };

            % label da rede da variância
            \node at (3,0.0) {\textbf{Rede da Variância}};

            % ----------------  Softplus + eps  ----------------
            \node[draw,rounded corners,minimum width=2.4cm,minimum height=0.9cm,
                below=0.8cm of sraw] (softp)
            {Softplus $+\;\varepsilon$};

            \draw[->] (sraw) -- (softp);

            % --------------------  Quadrado  -------------------
            \node[draw,rounded corners,minimum width=2.0cm,minimum height=0.9cm,
                below=0.8cm of softp] (square)
            {$(\cdot)^2$};

            \draw[->] (softp) -- (square);

            % saída final sigma^2(x)
            \node[neuron,fill=green!25,
            label={[yshift=-11pt]right:{$\sigma^2(x)$}}]
            (sfinal) at (3.9,-7) {};   % ↓ move para baixo

            \draw[->] (square) -- (sfinal);


            % =====================================================
            % ===============  NÓ FINAL forward()  ================
            % =====================================================

            \node[unicorn, right=3cm of $(qout)!0.5!(sfinal)$] (forward)
            {\texttt{forward()}};

            % setas q(x) -> forward
            \draw[->, thick] (qout.east) -- ++(0.8,0) |- (forward.west);

            % setas sigma^2(x) -> forward
            \draw[->, thick] (sfinal.east) -- ++(0.8,0) |- (forward.west);

            % nó de saída { q(x), sigma^2(x) }
            \node[neuron, fill=purple!20, right=1.4cm of forward,
            label=right:{$\{\,q(x),\;\sigma^2(x)\,\}$}] (final) {};

            \draw[->, thick] (forward) -- (final);

        \end{tikzpicture}
        \caption{Arquitetura completa com 10 neurônios ocultos em cada rede.
            As anotações indicam os números de pesos e vieses em cada camada linear;
            a função \texttt{forward()} apenas combina as saídas $q(x)$ e $\sigma^2(x)$.}
    \end{figure}
    \subsubsection*{Tamanho do modelo}

    \begin{table}[H]
        \centering
        \footnotesize
        \begin{tabular}{lcc}
            \toprule
            \textbf{Parâmetro}  & \textbf{Dimensão} & \textbf{Nº de parâmetros} \\
            \midrule
            q\_net.0.weight     & $10 \times 1$     & 10                        \\
            q\_net.0.bias       & $10$              & 10                        \\
            q\_net.2.weight     & $1 \times 10$     & 10                        \\
            q\_net.2.bias       & $1$               & 1                         \\
            sigma\_net.0.weight & $10 \times 1$     & 10                        \\
            sigma\_net.0.bias   & $10$              & 10                        \\
            sigma\_net.2.weight & $1 \times 10$     & 10                        \\
            sigma\_net.2.bias   & $1$               & 1                         \\
            \midrule
            \textbf{Total}      & ---               & \textbf{62}               \\
            \bottomrule
        \end{tabular}
        \caption{Parâmetros treináveis da rede neural quantílica utilizada no experimento.}
        \label{tab:parametros_quantil}
    \end{table}
    \subsubsection*{Treinamento e métricas}

\end{answer}


\end{document}
